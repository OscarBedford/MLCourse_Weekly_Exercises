{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPePO35xauRWlPFaHmAKApG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarBedford/MLCourse_Weekly_Exercises/blob/main/Exercise_10_10_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10- analogous to task 5 but predicting continuous subject age"
      ],
      "metadata": {
        "id": "pHEAQqCh0EEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install nilearn"
      ],
      "metadata": {
        "id": "QLjrDzMQPWn1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "from nilearn import datasets\n",
        "from nilearn.input_data import NiftiLabelsMasker\n",
        "from nilearn.image import index_img\n",
        "import nibabel as nib"
      ],
      "metadata": {
        "id": "aO5HSQivOUVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from datetime import datetime as dt"
      ],
      "metadata": {
        "id": "YXRWXQ7wPT4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from IPython import display\n",
        "display.set_matplotlib_formats('svg')"
      ],
      "metadata": {
        "id": "rasCRgwauhIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We import the data first in order to select the last 10 subjects\n",
        "%%capture\n",
        "brain_data = datasets.fetch_oasis_vbm(n_subjects=100)\n",
        "crad = datasets.fetch_atlas_craddock_2012()\n",
        "atlas_nii = index_img(crad['scorr_mean'], 1) # we fix this to 1\n",
        "masker = NiftiLabelsMasker(labels_img= atlas_nii, standardize=True)\n",
        "input_variables = masker.fit_transform(brain_data.gray_matter_maps)\n",
        "output_variable = StandardScaler().fit_transform(brain_data.ext_vars.age[:, None])[:, 0] # gives subject age on standard units after z-scoring"
      ],
      "metadata": {
        "id": "W1ItXNlyTFlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We prepare the X matrix and y vector, and we scale X\n",
        "X, y = input_variables[:, 0:50], output_variable\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "bbqeNNSsbbmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create the train-test splits by hand\n",
        "X_scaled_train = X_scaled[0:90,:]\n",
        "X_scaled_test = X_scaled[90:100,:]\n",
        "y_train = y[0:90]\n",
        "y_test  = y[90:100]"
      ],
      "metadata": {
        "id": "IBv7tBaA2NJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We preallocate the variable where we will store the timings\n",
        "running_secs = []"
      ],
      "metadata": {
        "id": "xLQ8ztVfsjEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are ready to iterate through the degree values:\n",
        "for d in list(range(1,5)):\n",
        "\n",
        "  X_scaled_train = X_scaled[0:90,:]                   # We re-instate X_scaled_train so that the initial value is always the same at the start of every iteration\n",
        "  X_scaled_test = X_scaled[90:100,:]                # Ditto for X_scaled_test\n",
        "\n",
        "  poly = PolynomialFeatures(degree=(d))                                 # We define the PolynomialFeatures model\n",
        "  X_scaled_train = poly.fit_transform(X_scaled_train)         # We fit_transform the training data to a n-th degree polynomial \n",
        "  X_scaled_test = poly.fit_transform(X_scaled_test)             # Ditto for the test data\n",
        "\n",
        "# We fit the logreg model on the transformed data to obtain training accuracies\n",
        "  start = dt.now()      # We start the timer here\n",
        "  b_ridge = BayesianRidge().fit(X_scaled_train, y_train)      # We fit the BayesianRidge model to the training data\n",
        "  halt = ((dt.now() - start).seconds * 1000)          # We stop the timer here and make sure to multiply the seconds by 1000 to get values in miliseconds\n",
        "  running_secs.append(halt)       # We append the current value of 'halt' to our pre-allocated 'running_secs' variable"
      ],
      "metadata": {
        "id": "x06I_ivtnSxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We're ready to plot\n",
        "sample=list(range(1,5))\n",
        "plt.style.use(\"default\")\n",
        "plt.scatter(sample,running_secs, s=50, alpha = 0.5, marker = 'o')\n",
        "plt.gca().set(\n",
        "    title=\"Bayesian Ridge training model runtime (ms) as a function of polynomial degree (1-4) for 50 ROIs\",\n",
        "    xlabel=\"Polynomial degree (1, 2, 3 or 4)\",\n",
        "    ylabel=\"Miliseconds\",\n",
        "    xticks = (sample)\n",
        ")\n",
        "plt.plot(sample,running_secs)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HoXtx_31ybGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ODsCqb8808Wj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}