{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNaSiNxQ8QcrrSClTvnXyj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarBedford/MLCourse_Weekly_Exercises/blob/main/Week2_partB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset B (regression): for the second set of 5 small programming tasks, use the Haxby dataset provided by the nilearn package, which can be downloaded using the code below. This is a dataset of functional brain scans (functional MRI measurements from one subject) acquired while individuals watched people’s faces or house pictures."
      ],
      "metadata": {
        "id": "v8uiBwwQokmt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "ZGKMKO3bkjo5",
        "outputId": "24a9f885-fdbd-4fba-ac24-ef4ab3ab8bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
            "\n",
            "* deprecated from version: 3.0\n",
            "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The only relevant horizontal brain slice has 739 voxels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
            "\n",
            "* deprecated from version: 3.0\n",
            "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The only relevant horizontal brain slice has 739 voxels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nilearn/plotting/displays/_slicers.py:1333: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  fraction * (x1 - x0), y1 - y0])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<nilearn.plotting.displays._slicers.ZSlicer at 0x7fb6567f4690>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 208.8x165.6 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from nilearn import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "from nilearn.image import new_img_like\n",
        "from nilearn.plotting import plot_stat_map\n",
        "from matplotlib import pylab as plt\n",
        "\n",
        "haxby_dataset = datasets.fetch_haxby(subjects=1)\n",
        "mask_filename = haxby_dataset.mask\n",
        "mask_img = nib.load(mask_filename)\n",
        "process_mask = mask_img.get_data()\n",
        "picked_slice = 29\n",
        "process_mask[..., (picked_slice + 1):] = 0\n",
        "process_mask[..., :picked_slice] = 0\n",
        "process_mask[:, 30:] = 0 # zero out anterior “half” of the brain\n",
        "process_mask_img = new_img_like(mask_img, process_mask)\n",
        "\n",
        "from nilearn.input_data import NiftiMasker\n",
        "nifti_masker = NiftiMasker(smoothing_fwhm=8,\n",
        "mask_img=process_mask_img)\n",
        "func_filename = haxby_dataset.func[0]\n",
        "fmri_masked = nifti_masker.fit_transform(func_filename)\n",
        "labels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
        "conditions = labels['labels']\n",
        "condition_mask = conditions.isin(['face', 'house'])\n",
        "fmri_masked = fmri_masked[condition_mask]\n",
        "output_variable = np.array(conditions[condition_mask] == 'face',\n",
        "dtype=int)\n",
        "\n",
        "print('The only relevant horizontal brain slice has %i voxels.' %\n",
        "process_mask[..., picked_slice].sum())\n",
        "\n",
        "from nilearn import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "from nilearn.image import new_img_like\n",
        "from nilearn.plotting import plot_stat_map\n",
        "from matplotlib import pylab as plt\n",
        "\n",
        "haxby_dataset = datasets.fetch_haxby(subjects=1)\n",
        "mask_filename = haxby_dataset.mask\n",
        "mask_img = nib.load(mask_filename)\n",
        "process_mask = mask_img.get_data()\n",
        "picked_slice = 29\n",
        "process_mask[..., (picked_slice + 1):] = 0\n",
        "process_mask[..., :picked_slice] = 0\n",
        "process_mask[:, 30:] = 0 # zero out anterior “half” of the brain\n",
        "process_mask_img = new_img_like(mask_img, process_mask)\n",
        "\n",
        "from nilearn.input_data import NiftiMasker\n",
        "nifti_masker = NiftiMasker(smoothing_fwhm=8,\n",
        "mask_img=process_mask_img)\n",
        "func_filename = haxby_dataset.func[0]\n",
        "fmri_masked = nifti_masker.fit_transform(func_filename)\n",
        "labels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
        "conditions = labels['labels']\n",
        "condition_mask = conditions.isin(['face', 'house'])\n",
        "fmri_masked = fmri_masked[condition_mask]\n",
        "output_variable = np.array(conditions[condition_mask] == 'face',\n",
        "dtype=int)\n",
        "\n",
        "print('The only relevant horizontal brain slice has %i voxels.' %\n",
        "process_mask[..., picked_slice].sum())\n",
        "\n",
        "#plot that slice to get an impression of where the input variables are in the brain \n",
        "plot_stat_map(process_mask_img, cut_coords=[-9],\n",
        "display_mode=\"z\", cmap=plt.cm.RdBu_r)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: since there are many more input variables in this dataset, for ll of the following questions only generate plots of the first 17 input variables (your models should still be trained using all input ariables). For Q8 and Q9 use an 80/20% train/test split.\n",
        "\n",
        "6. analogous to task 1 but using sklearn.linear_model.Ridge(default hyperparameters) instead of logistic regression, since the target is now continuous.\n",
        "\n",
        "  Use sklearn.linear_model.Ridge(default hyperparameters) trained on all input_variables to perform uncertainty estimation. Draw 200 bootstrap samples from the dataset, and for each of these bootstrap datasets, fit your model on all 216 subjects (you will train 200 models). Plot the distribution of model parameters(.coef_)using pyplot.boxplot(). The distribution of the model parameters should be on the y-axis and the first 17 input variables on the x axis; the mean of each box is the original point estimate of the model coefficient (i.e., the original dataset, not the bootstrap data). "
      ],
      "metadata": {
        "id": "FVIMoRQvlksI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_variables = fmri_masked\n",
        "input_variables.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcMAfI-7wFcf",
        "outputId": "62e7e8fb-f03e-409a-d112-f5873a846fa3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(216, 739)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "NEoaEPMtyHeB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create one bootstrap sample containing 216 observations to make sure we have everything we need\n",
        "boot = resample(input_variables, replace=True, n_samples=216)\n",
        "print (boot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zb6wpnjzDuc",
        "outputId": "1d63f041-52c7-4f04-bd0c-63f1b123a194"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 739)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like the size of our \"boot\" sample is correct, because it is the same as the original data. But we will need 200 of these samples, so let's make use of a for loop to create them iteratively:"
      ],
      "metadata": {
        "id": "Zdj29RHB9-gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the number of iterations\n",
        "n_iterations = 200\n",
        "# Pre-allocating the array where the coefficients of the 200 models will be appended\n",
        "coefficients = []\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    X_train = resample(input_variables, replace=True, n_samples=216) # X_train is the given bootstrap sample in the current iteration\n",
        "    X_train = scaler.fit_transform(X_train) # Here we run the scaler on every iteration\n",
        "    y_train = output_variable # y_train will remain the same as the original sample across iterations\n",
        "    LinReg_boot = LinearRegression().fit(X_train,y_train) # We fit the LR model to the current bootstrap sample\n",
        "    coefficients.append(LinReg_boot.coef_) # Store the coefficients in the \"coefficients\" array\n",
        "    score = LinReg_boot.score(X_train, y_train) # We will also export the score for each bootstrap model (...)\n",
        "    print('Accuracy: %.3f (%.3f)' % ((score), std(score))) # (...) and we will print it to make sure every model is different"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac8P1h6T9q9f",
        "outputId": "cc8d8e7c-65f2-475a-e1ef-5afb3345262f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.705 (0.000)\n",
            "Accuracy: 0.651 (0.000)\n",
            "Accuracy: 0.645 (0.000)\n",
            "Accuracy: 0.637 (0.000)\n",
            "Accuracy: 0.634 (0.000)\n",
            "Accuracy: 0.614 (0.000)\n",
            "Accuracy: 0.609 (0.000)\n",
            "Accuracy: 0.698 (0.000)\n",
            "Accuracy: 0.600 (0.000)\n",
            "Accuracy: 0.596 (0.000)\n",
            "Accuracy: 0.645 (0.000)\n",
            "Accuracy: 0.606 (0.000)\n",
            "Accuracy: 0.740 (0.000)\n",
            "Accuracy: 0.752 (0.000)\n",
            "Accuracy: 0.596 (0.000)\n",
            "Accuracy: 0.535 (0.000)\n",
            "Accuracy: 0.652 (0.000)\n",
            "Accuracy: 0.639 (0.000)\n",
            "Accuracy: 0.576 (0.000)\n",
            "Accuracy: 0.633 (0.000)\n",
            "Accuracy: 0.601 (0.000)\n",
            "Accuracy: 0.614 (0.000)\n",
            "Accuracy: 0.702 (0.000)\n",
            "Accuracy: 0.603 (0.000)\n",
            "Accuracy: 0.636 (0.000)\n",
            "Accuracy: 0.627 (0.000)\n",
            "Accuracy: 0.674 (0.000)\n",
            "Accuracy: 0.734 (0.000)\n",
            "Accuracy: 0.596 (0.000)\n",
            "Accuracy: 0.620 (0.000)\n",
            "Accuracy: 0.626 (0.000)\n",
            "Accuracy: 0.571 (0.000)\n",
            "Accuracy: 0.612 (0.000)\n",
            "Accuracy: 0.667 (0.000)\n",
            "Accuracy: 0.594 (0.000)\n",
            "Accuracy: 0.568 (0.000)\n",
            "Accuracy: 0.706 (0.000)\n",
            "Accuracy: 0.668 (0.000)\n",
            "Accuracy: 0.580 (0.000)\n",
            "Accuracy: 0.654 (0.000)\n",
            "Accuracy: 0.560 (0.000)\n",
            "Accuracy: 0.610 (0.000)\n",
            "Accuracy: 0.617 (0.000)\n",
            "Accuracy: 0.599 (0.000)\n",
            "Accuracy: 0.648 (0.000)\n",
            "Accuracy: 0.641 (0.000)\n",
            "Accuracy: 0.589 (0.000)\n",
            "Accuracy: 0.626 (0.000)\n",
            "Accuracy: 0.607 (0.000)\n",
            "Accuracy: 0.646 (0.000)\n",
            "Accuracy: 0.643 (0.000)\n",
            "Accuracy: 0.638 (0.000)\n",
            "Accuracy: 0.578 (0.000)\n",
            "Accuracy: 0.599 (0.000)\n",
            "Accuracy: 0.646 (0.000)\n",
            "Accuracy: 0.616 (0.000)\n",
            "Accuracy: 0.625 (0.000)\n",
            "Accuracy: 0.609 (0.000)\n",
            "Accuracy: 0.646 (0.000)\n",
            "Accuracy: 0.580 (0.000)\n",
            "Accuracy: 0.633 (0.000)\n",
            "Accuracy: 0.618 (0.000)\n",
            "Accuracy: 0.676 (0.000)\n",
            "Accuracy: 0.682 (0.000)\n",
            "Accuracy: 0.612 (0.000)\n",
            "Accuracy: 0.624 (0.000)\n",
            "Accuracy: 0.645 (0.000)\n",
            "Accuracy: 0.690 (0.000)\n",
            "Accuracy: 0.600 (0.000)\n",
            "Accuracy: 0.716 (0.000)\n",
            "Accuracy: 0.558 (0.000)\n",
            "Accuracy: 0.645 (0.000)\n",
            "Accuracy: 0.582 (0.000)\n",
            "Accuracy: 0.609 (0.000)\n",
            "Accuracy: 0.604 (0.000)\n",
            "Accuracy: 0.573 (0.000)\n",
            "Accuracy: 0.648 (0.000)\n",
            "Accuracy: 0.556 (0.000)\n",
            "Accuracy: 0.664 (0.000)\n",
            "Accuracy: 0.631 (0.000)\n",
            "Accuracy: 0.707 (0.000)\n",
            "Accuracy: 0.647 (0.000)\n",
            "Accuracy: 0.687 (0.000)\n",
            "Accuracy: 0.659 (0.000)\n",
            "Accuracy: 0.573 (0.000)\n",
            "Accuracy: 0.616 (0.000)\n",
            "Accuracy: 0.572 (0.000)\n",
            "Accuracy: 0.603 (0.000)\n",
            "Accuracy: 0.585 (0.000)\n",
            "Accuracy: 0.633 (0.000)\n",
            "Accuracy: 0.640 (0.000)\n",
            "Accuracy: 0.643 (0.000)\n",
            "Accuracy: 0.610 (0.000)\n",
            "Accuracy: 0.633 (0.000)\n",
            "Accuracy: 0.681 (0.000)\n",
            "Accuracy: 0.614 (0.000)\n",
            "Accuracy: 0.588 (0.000)\n",
            "Accuracy: 0.583 (0.000)\n",
            "Accuracy: 0.607 (0.000)\n",
            "Accuracy: 0.645 (0.000)\n",
            "Accuracy: 0.631 (0.000)\n",
            "Accuracy: 0.631 (0.000)\n",
            "Accuracy: 0.572 (0.000)\n",
            "Accuracy: 0.627 (0.000)\n",
            "Accuracy: 0.680 (0.000)\n",
            "Accuracy: 0.642 (0.000)\n",
            "Accuracy: 0.587 (0.000)\n",
            "Accuracy: 0.651 (0.000)\n",
            "Accuracy: 0.603 (0.000)\n",
            "Accuracy: 0.632 (0.000)\n",
            "Accuracy: 0.703 (0.000)\n",
            "Accuracy: 0.610 (0.000)\n",
            "Accuracy: 0.668 (0.000)\n",
            "Accuracy: 0.661 (0.000)\n",
            "Accuracy: 0.700 (0.000)\n",
            "Accuracy: 0.694 (0.000)\n",
            "Accuracy: 0.596 (0.000)\n",
            "Accuracy: 0.582 (0.000)\n",
            "Accuracy: 0.584 (0.000)\n",
            "Accuracy: 0.610 (0.000)\n",
            "Accuracy: 0.677 (0.000)\n",
            "Accuracy: 0.563 (0.000)\n",
            "Accuracy: 0.634 (0.000)\n",
            "Accuracy: 0.583 (0.000)\n",
            "Accuracy: 0.659 (0.000)\n",
            "Accuracy: 0.580 (0.000)\n",
            "Accuracy: 0.641 (0.000)\n",
            "Accuracy: 0.627 (0.000)\n",
            "Accuracy: 0.671 (0.000)\n",
            "Accuracy: 0.648 (0.000)\n",
            "Accuracy: 0.627 (0.000)\n",
            "Accuracy: 0.617 (0.000)\n",
            "Accuracy: 0.637 (0.000)\n",
            "Accuracy: 0.624 (0.000)\n",
            "Accuracy: 0.604 (0.000)\n",
            "Accuracy: 0.611 (0.000)\n",
            "Accuracy: 0.599 (0.000)\n",
            "Accuracy: 0.603 (0.000)\n",
            "Accuracy: 0.708 (0.000)\n",
            "Accuracy: 0.587 (0.000)\n",
            "Accuracy: 0.650 (0.000)\n",
            "Accuracy: 0.571 (0.000)\n",
            "Accuracy: 0.646 (0.000)\n",
            "Accuracy: 0.633 (0.000)\n",
            "Accuracy: 0.644 (0.000)\n",
            "Accuracy: 0.639 (0.000)\n",
            "Accuracy: 0.613 (0.000)\n",
            "Accuracy: 0.693 (0.000)\n",
            "Accuracy: 0.610 (0.000)\n",
            "Accuracy: 0.670 (0.000)\n",
            "Accuracy: 0.619 (0.000)\n",
            "Accuracy: 0.656 (0.000)\n",
            "Accuracy: 0.616 (0.000)\n",
            "Accuracy: 0.654 (0.000)\n",
            "Accuracy: 0.681 (0.000)\n",
            "Accuracy: 0.619 (0.000)\n",
            "Accuracy: 0.641 (0.000)\n",
            "Accuracy: 0.623 (0.000)\n",
            "Accuracy: 0.659 (0.000)\n",
            "Accuracy: 0.657 (0.000)\n",
            "Accuracy: 0.672 (0.000)\n",
            "Accuracy: 0.648 (0.000)\n",
            "Accuracy: 0.590 (0.000)\n",
            "Accuracy: 0.562 (0.000)\n",
            "Accuracy: 0.582 (0.000)\n",
            "Accuracy: 0.576 (0.000)\n",
            "Accuracy: 0.626 (0.000)\n",
            "Accuracy: 0.722 (0.000)\n",
            "Accuracy: 0.595 (0.000)\n",
            "Accuracy: 0.719 (0.000)\n",
            "Accuracy: 0.585 (0.000)\n",
            "Accuracy: 0.622 (0.000)\n",
            "Accuracy: 0.596 (0.000)\n",
            "Accuracy: 0.619 (0.000)\n",
            "Accuracy: 0.632 (0.000)\n",
            "Accuracy: 0.649 (0.000)\n",
            "Accuracy: 0.601 (0.000)\n",
            "Accuracy: 0.611 (0.000)\n",
            "Accuracy: 0.650 (0.000)\n",
            "Accuracy: 0.672 (0.000)\n",
            "Accuracy: 0.617 (0.000)\n",
            "Accuracy: 0.688 (0.000)\n",
            "Accuracy: 0.565 (0.000)\n",
            "Accuracy: 0.605 (0.000)\n",
            "Accuracy: 0.641 (0.000)\n",
            "Accuracy: 0.640 (0.000)\n",
            "Accuracy: 0.611 (0.000)\n",
            "Accuracy: 0.575 (0.000)\n",
            "Accuracy: 0.606 (0.000)\n",
            "Accuracy: 0.636 (0.000)\n",
            "Accuracy: 0.623 (0.000)\n",
            "Accuracy: 0.605 (0.000)\n",
            "Accuracy: 0.671 (0.000)\n",
            "Accuracy: 0.622 (0.000)\n",
            "Accuracy: 0.543 (0.000)\n",
            "Accuracy: 0.687 (0.000)\n",
            "Accuracy: 0.633 (0.000)\n",
            "Accuracy: 0.673 (0.000)\n",
            "Accuracy: 0.654 (0.000)\n",
            "Accuracy: 0.629 (0.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall model accuracies are indeed different from each other, which is good, and they seem to hover around the 0.6 value. Let's compute the model accuracy for the model with the original data to see if it's better than what we get with bootstrap samples:"
      ],
      "metadata": {
        "id": "z_igHPlK-_Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_variables = scaler.fit_transform(input_variables) # We replicate the pipeline by first standardizing the data \n",
        "LinReg = LinearRegression().fit(input_variables,output_variable)\n",
        "score = LinReg.score(input_variables, output_variable)\n",
        "print('Accuracy: %.3f (%.3f)' % ((score), std(score)))\n",
        "usermeans = LinReg.coef_ # We will store the model paramaters in a variable called \"usermeans\" to be used later"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk43nAas_Caz",
        "outputId": "da1e7c4e-504a-40ab-e24a-75cf2cb81389"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.000 (0.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "usermeans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leNTxWRB_VKK",
        "outputId": "ff222df9-eabf-4a92-c515-f0bae9285c91"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.11818326e-02, -5.74960858e-02, -9.66362469e-03,  5.41394278e-02,\n",
              "        1.90300327e-02, -3.45373750e-02,  4.62020114e-02, -1.67341344e-03,\n",
              "        2.05154344e-03,  5.34438342e-03, -4.46547717e-02, -2.68764533e-02,\n",
              "        4.20630947e-02,  9.97167081e-03, -3.83019000e-02,  2.26146914e-02,\n",
              "        6.34077191e-03,  5.31657971e-02, -3.68162617e-03, -1.09592946e-02,\n",
              "       -3.38747874e-02,  3.05605028e-02,  1.38339996e-02, -3.58582325e-02,\n",
              "       -5.73652051e-03, -1.24922674e-03,  3.89917335e-03, -3.46667171e-02,\n",
              "        2.43538618e-03,  1.47945229e-02, -1.85577068e-02, -2.70750262e-02,\n",
              "       -5.34760877e-02, -4.78618704e-02,  4.85054497e-03,  7.69471237e-03,\n",
              "        8.15391727e-03,  5.58814332e-02,  3.77442054e-02, -4.59015146e-02,\n",
              "       -2.51988787e-02,  1.59476046e-02, -3.60473283e-02,  4.42414079e-03,\n",
              "        1.39283426e-02, -2.23322064e-02, -3.42618302e-02, -3.30904722e-02,\n",
              "       -4.76845913e-02, -2.88536344e-02, -5.64932786e-02, -6.66621998e-02,\n",
              "        4.58983816e-02,  4.09583040e-02,  6.27979413e-02,  2.15635318e-02,\n",
              "        1.63460849e-03,  5.38449362e-02, -2.41629053e-02, -1.94096044e-02,\n",
              "       -1.60241798e-02, -2.58621592e-02, -9.08419117e-03,  1.27647454e-02,\n",
              "       -1.17546646e-03,  1.06127895e-02,  3.85384075e-03, -3.62769514e-02,\n",
              "        5.03013283e-03, -7.35678058e-03, -4.93019894e-02,  6.87979907e-03,\n",
              "        2.25574858e-02,  3.35378665e-03,  1.28303468e-02,  2.30888743e-03,\n",
              "        1.23152109e-02, -1.36877522e-02, -1.23503348e-02,  2.87526343e-02,\n",
              "        3.99352238e-02,  1.82955191e-02,  2.17922106e-02,  4.50509377e-02,\n",
              "        1.48148332e-02,  3.52333188e-02, -1.66496541e-02, -3.10379844e-02,\n",
              "        3.33067849e-02, -4.00963891e-03, -2.63897609e-02, -3.72549668e-02,\n",
              "        2.52168495e-02,  4.39615808e-02,  5.78801371e-02,  1.09257642e-02,\n",
              "       -3.50992307e-02, -4.57898490e-02, -2.58889999e-02, -2.04289537e-02,\n",
              "       -1.73222609e-02, -2.56071407e-02, -4.84696366e-02,  4.04272527e-02,\n",
              "        1.88271739e-02, -2.85101421e-02,  2.69800760e-02,  1.86034162e-02,\n",
              "        6.43408950e-03, -1.03674056e-02, -1.66930854e-02,  2.03719549e-02,\n",
              "        3.51660363e-02,  4.06719223e-02,  1.11976946e-02, -3.43513750e-02,\n",
              "       -4.52829972e-02, -3.40162069e-02, -1.95119120e-02, -1.28295273e-02,\n",
              "       -2.60895062e-02, -2.93742269e-02,  3.55248488e-02,  3.69818434e-02,\n",
              "        3.93964238e-02, -8.11711233e-03, -1.58523191e-02, -1.22883683e-03,\n",
              "       -7.46572064e-03, -2.66670287e-02, -2.96823867e-02, -1.96995474e-02,\n",
              "       -9.30359773e-03, -1.51321711e-02,  4.80927946e-03,  7.18135238e-02,\n",
              "        3.37979607e-02,  1.93304252e-02,  3.43758389e-02,  3.36463079e-02,\n",
              "        1.51899159e-02,  2.31963992e-02,  1.56782754e-03,  6.72003627e-03,\n",
              "        2.38606185e-02, -1.14835287e-02, -2.08299663e-02, -8.23873375e-03,\n",
              "        4.39423919e-02,  3.83832119e-02, -9.49267019e-03, -1.08069843e-02,\n",
              "        1.12517811e-02, -9.28711891e-03, -1.86197460e-03,  6.11560121e-02,\n",
              "       -7.24797137e-04, -4.92019067e-03,  3.46404649e-02,  2.74280086e-02,\n",
              "       -2.88652405e-02, -2.35146806e-02,  4.99844998e-02, -4.10815887e-02,\n",
              "        2.89251562e-02,  8.77990678e-05, -2.76943892e-02, -4.32359688e-02,\n",
              "        4.62069325e-02,  4.56847250e-02,  3.75497639e-02,  2.85380185e-02,\n",
              "        2.99862884e-02,  2.71683466e-02, -3.83421872e-03,  9.36887600e-03,\n",
              "       -1.96856000e-02, -2.01769657e-02,  1.91146918e-02,  9.23506450e-03,\n",
              "       -3.89929526e-02,  1.55641548e-02,  1.14467934e-01, -1.03955921e-02,\n",
              "       -5.83979003e-02,  2.61791050e-02,  1.73774250e-02, -1.46405054e-02,\n",
              "       -2.61274409e-02,  1.45138688e-02, -4.33775932e-02, -2.41453275e-02,\n",
              "        1.94062237e-02,  1.86398439e-02,  3.70503366e-02, -2.49478593e-02,\n",
              "       -3.08407973e-02, -1.54729923e-02, -3.82819846e-02, -1.89585239e-02,\n",
              "       -5.50455088e-03, -8.09335709e-03, -4.80674487e-03, -3.36997621e-02,\n",
              "        1.03280600e-02, -4.67038597e-04,  1.30276093e-02,  3.80457193e-02,\n",
              "        1.33453738e-02, -2.51934025e-02, -3.17679979e-02,  2.49442160e-02,\n",
              "       -6.98911864e-03, -4.40193340e-02,  1.02853291e-02,  3.52242813e-02,\n",
              "        3.79414856e-02, -3.87643948e-02, -5.55818006e-02, -8.88369046e-03,\n",
              "       -5.06489947e-02, -6.08856119e-02, -3.96293495e-03,  6.13326877e-02,\n",
              "        3.61972186e-03, -5.95699400e-02, -8.24807212e-03,  3.35584432e-02,\n",
              "        5.68014793e-02,  6.72989786e-02,  3.11920233e-02, -2.16145702e-02,\n",
              "       -4.20613959e-02,  2.14894898e-02,  2.58229114e-02, -1.91786122e-02,\n",
              "        1.98706165e-02,  2.63506901e-02,  1.74298454e-02,  2.67175063e-02,\n",
              "        1.72265042e-02,  1.57509632e-02, -9.62210819e-03,  6.46799803e-03,\n",
              "        2.39419490e-02,  2.62325481e-02, -1.37766618e-02, -1.74613632e-02,\n",
              "        2.98161134e-02, -2.16522180e-02,  8.15623254e-03,  4.46867421e-02,\n",
              "        7.29782656e-02,  6.28941581e-02,  7.53662884e-02,  4.25972156e-02,\n",
              "        2.32005995e-02, -1.73235573e-02, -4.35408354e-02,  9.91535187e-03,\n",
              "       -2.77473405e-02, -3.73125970e-02,  3.26294750e-02,  4.53207418e-02,\n",
              "        5.77071775e-03, -3.48578915e-02,  4.84516397e-02,  8.53718147e-02,\n",
              "       -4.23236825e-02, -5.30804284e-02, -1.64628192e-03,  2.44232360e-02,\n",
              "        4.48457859e-02,  3.50212958e-03,  3.92854586e-03,  2.44351057e-03,\n",
              "       -5.13847657e-02, -5.61761111e-03,  3.22332382e-02,  2.40531694e-02,\n",
              "       -2.33030971e-02, -2.33544083e-03,  6.43007681e-02, -3.17267999e-02,\n",
              "       -7.92209208e-02, -1.05737941e-02,  1.96800921e-02, -1.24368342e-02,\n",
              "       -9.75097194e-02, -4.53275181e-02,  9.03740078e-02,  1.05921114e-02,\n",
              "       -1.63241923e-02,  1.89296342e-02, -6.14123326e-03,  2.53683999e-02,\n",
              "       -1.20742340e-02, -3.01182531e-02, -7.11475909e-02, -1.27043515e-01,\n",
              "       -1.05031893e-01, -4.26096693e-02, -3.54456417e-02, -6.85174763e-02,\n",
              "       -1.59981661e-04,  6.20005764e-02, -3.52693312e-02, -4.34713140e-02,\n",
              "        2.72827540e-02,  3.02367713e-02,  1.69689488e-02, -4.14100513e-02,\n",
              "       -9.64350626e-02, -3.60608026e-02, -3.04287635e-02,  1.01997890e-02,\n",
              "       -7.14940112e-03, -4.79572862e-02, -8.54627490e-02, -4.33759540e-02,\n",
              "       -5.02431579e-03,  5.53081371e-02, -2.78146248e-02, -6.44436926e-02,\n",
              "       -2.94084698e-02,  2.03494877e-02, -2.95186462e-03, -6.07376918e-02,\n",
              "        1.53614907e-02,  3.67141739e-02,  2.22795717e-02,  2.92922184e-02,\n",
              "        3.69190425e-02,  6.00544810e-02,  3.09390314e-02, -5.56008965e-02,\n",
              "       -3.55690941e-02, -1.58153176e-02,  7.63775855e-02, -1.57541577e-02,\n",
              "        5.44964373e-02, -5.92576563e-02, -3.89101170e-02,  2.69472692e-03,\n",
              "        9.48228687e-02,  4.05107215e-02,  2.60311132e-03, -4.28084400e-04,\n",
              "        7.67028332e-02,  1.14725292e-01, -3.94103490e-02,  2.45198049e-02,\n",
              "        5.14391102e-02, -1.07856961e-02, -4.63768989e-02, -2.74547767e-02,\n",
              "        4.10400219e-02,  3.57767530e-02, -1.71789974e-02,  2.44014841e-02,\n",
              "        4.73334864e-02,  1.13293566e-01, -1.53097948e-02,  5.21926582e-02,\n",
              "       -1.89459305e-02, -4.60996479e-02, -1.13458168e-02,  2.20162179e-02,\n",
              "        4.93982295e-03, -4.99080755e-02, -3.98437344e-02,  6.89127063e-03,\n",
              "       -4.96813953e-02, -1.35807786e-02, -5.97560406e-03, -4.55166288e-02,\n",
              "       -5.72287291e-02, -3.55714746e-02,  1.43857943e-02,  1.69719402e-02,\n",
              "       -3.56899276e-02, -2.15764102e-02,  7.77103193e-03,  2.46167835e-02,\n",
              "       -6.30715340e-02,  2.11674739e-02,  4.79832366e-02,  8.12112167e-03,\n",
              "       -1.56889595e-02,  9.58302896e-03, -9.43859015e-03, -2.74286103e-02,\n",
              "       -7.51022995e-03, -2.17172783e-02, -3.89257222e-02, -3.33837904e-02,\n",
              "       -2.41167434e-02, -4.15043235e-02, -3.69600430e-02, -1.78192332e-02,\n",
              "       -1.12560857e-02, -1.76264830e-02, -3.88271883e-02,  1.82594918e-02,\n",
              "        7.71551579e-02, -4.81120646e-02, -4.77124304e-02, -2.13274267e-03,\n",
              "        5.38735874e-02,  4.26313430e-02, -4.46605962e-04, -1.45267667e-02,\n",
              "       -8.56152643e-03,  7.62565583e-02,  1.00274451e-01,  1.48395915e-02,\n",
              "       -1.75556391e-02, -1.17971748e-02, -2.23281384e-02, -2.74392553e-02,\n",
              "       -9.56410170e-03,  2.71281879e-02,  2.52198949e-02, -3.32041383e-02,\n",
              "       -4.74169552e-02,  2.37058215e-02,  3.78662869e-02, -8.18321034e-02,\n",
              "        1.21864127e-02,  2.47554854e-04,  1.78361200e-02,  2.89856251e-02,\n",
              "       -5.59132965e-03, -4.74195369e-02, -1.30293136e-02,  8.74215141e-02,\n",
              "        1.56001784e-02, -8.11292008e-02, -1.74998976e-02,  2.94268094e-02,\n",
              "       -2.97650825e-02, -4.26413640e-02, -2.14574784e-02,  4.49200012e-02,\n",
              "        6.37213290e-02, -3.38512212e-02, -4.97348644e-02, -1.56328119e-02,\n",
              "       -2.46658791e-02,  5.70879597e-03,  9.04585868e-02, -3.84761617e-02,\n",
              "       -3.79442377e-03,  1.64382719e-02, -7.89313018e-03, -5.13664223e-02,\n",
              "       -1.02375038e-02,  9.13340785e-03, -6.59326091e-02, -5.85848168e-02,\n",
              "        6.89268857e-02,  1.08774446e-01,  1.56861618e-02, -5.49764335e-02,\n",
              "       -6.53692484e-02,  9.34222620e-03,  4.16257158e-02, -2.77152490e-02,\n",
              "        2.62233731e-03,  3.00874710e-02, -1.30750500e-02,  4.33702618e-02,\n",
              "        1.11919649e-01, -6.73044175e-02,  2.21160594e-02,  4.26683761e-02,\n",
              "        4.07047272e-02,  1.34548396e-02, -3.95982526e-03, -2.42830664e-02,\n",
              "       -1.18611166e-02,  3.11023407e-02,  8.21587592e-02,  8.59367698e-02,\n",
              "       -8.06637108e-05, -3.68364416e-02, -4.60904129e-02, -1.93521827e-02,\n",
              "       -2.17877738e-02, -5.83874509e-02,  5.95714478e-03,  4.34722304e-02,\n",
              "       -2.94094682e-02, -3.26234996e-02,  5.02055790e-03, -4.92965579e-02,\n",
              "        9.48576815e-03,  6.97015738e-03,  1.13737043e-02, -7.23640295e-03,\n",
              "       -4.90888879e-02, -4.65499386e-02, -3.83848231e-03, -2.08404846e-03,\n",
              "        3.07159312e-02,  2.93054786e-02, -3.65044959e-02,  3.15705016e-02,\n",
              "        4.20710221e-02,  3.23471613e-04, -6.64996170e-03, -6.94811717e-02,\n",
              "       -7.00859949e-02,  1.86781660e-02, -1.28410198e-03, -3.81610990e-02,\n",
              "       -2.65901480e-02,  6.73282519e-02,  9.49854031e-03, -5.71588799e-03,\n",
              "        3.95058794e-03,  1.43133905e-02, -1.23097748e-03, -2.96963062e-02,\n",
              "       -1.77791715e-02,  2.07456946e-03,  4.46763821e-02,  2.80298740e-02,\n",
              "       -4.06323858e-02,  3.30646709e-02,  3.24883945e-02, -3.57611571e-03,\n",
              "        5.28282709e-02, -3.13361152e-03, -3.77502218e-02,  9.53540877e-02,\n",
              "        7.44607300e-02, -1.13349902e-02,  2.11890154e-02, -3.06471586e-02,\n",
              "        8.84437636e-02,  4.98840250e-02,  3.28457579e-02,  4.94868867e-02,\n",
              "        5.53210303e-02,  3.50764627e-03, -4.59046569e-03,  3.24632972e-02,\n",
              "        4.95034270e-02, -9.05469991e-04, -6.58484399e-02, -6.20178506e-02,\n",
              "       -3.58506963e-02, -2.96639465e-03,  4.23887298e-02, -1.54686477e-02,\n",
              "       -9.98651609e-02, -3.50929312e-02, -3.70815694e-02, -6.14920780e-02,\n",
              "        1.40109491e-02,  3.83932181e-02,  1.88258048e-02,  5.37048979e-03,\n",
              "        4.64573503e-03,  3.38429562e-03, -2.21279263e-03,  2.09378973e-02,\n",
              "        7.13492930e-03,  3.89856845e-02,  5.03295846e-02,  1.96741857e-02,\n",
              "       -1.20414617e-02, -7.43635744e-03,  1.25243273e-02,  1.54093662e-02,\n",
              "        4.83646896e-03, -3.05622704e-02, -7.57569075e-02, -7.79689252e-02,\n",
              "       -7.55287856e-02,  4.36651297e-02,  5.87209575e-02, -4.25784364e-02,\n",
              "       -1.32365506e-02, -2.61399765e-02, -3.94949801e-02, -5.07810824e-02,\n",
              "       -5.73047586e-02, -8.70322064e-02, -1.04593234e-02,  5.39226383e-02,\n",
              "        3.72341909e-02,  1.97486207e-02,  2.89064925e-02,  3.36327627e-02,\n",
              "        3.01179178e-02,  3.04836053e-02,  5.54955378e-02,  3.62027586e-02,\n",
              "        4.44861464e-02, -3.69137041e-02,  3.99019010e-02,  3.48634422e-02,\n",
              "        1.90158300e-02, -3.92783526e-03, -2.20230352e-02, -6.02592491e-02,\n",
              "       -1.01728588e-01, -8.79269466e-02, -7.36686401e-03,  4.06734757e-02,\n",
              "        1.27889868e-03, -1.45797059e-02,  2.93357540e-02,  2.42426172e-02,\n",
              "        7.07864016e-03, -4.79871556e-02, -4.44901921e-02, -1.21805826e-02,\n",
              "        4.07855101e-02, -3.61813419e-02,  1.78964362e-02, -4.77202125e-02,\n",
              "        2.88723577e-02,  7.18921199e-02,  4.42572087e-02, -3.56826894e-02,\n",
              "       -7.36195520e-02,  5.83360530e-03,  1.03201844e-01,  2.20583379e-02,\n",
              "       -5.09421267e-02,  1.26160868e-02, -1.50474850e-02, -3.19490731e-02,\n",
              "       -4.25146259e-02, -6.44967556e-02, -5.43460399e-02,  5.28218132e-03,\n",
              "        1.44891134e-02,  5.04889525e-02,  3.12257856e-02, -1.66017972e-02,\n",
              "        6.01535700e-02,  3.57718300e-03, -9.02305022e-02, -1.07946163e-02,\n",
              "        1.31444350e-01,  1.59942359e-02, -8.42433199e-02, -9.23475996e-03,\n",
              "        1.40914693e-04, -5.56240231e-03,  8.17269310e-02,  6.09642267e-02,\n",
              "       -2.10009888e-02, -9.27700009e-03,  2.04988406e-03, -3.01813483e-02,\n",
              "       -3.22377980e-02, -6.65271580e-02,  1.27135264e-03, -4.30394486e-02,\n",
              "        2.47461209e-03,  9.76420417e-02,  2.10950803e-02, -4.13159877e-02,\n",
              "        4.81417123e-03,  1.14551578e-02, -4.51815128e-02,  2.55975220e-02,\n",
              "        3.89584005e-02,  1.26657803e-02, -4.95566288e-03, -9.76704992e-03,\n",
              "       -5.13535142e-02,  3.07506919e-02,  4.16692011e-02,  3.01844366e-02,\n",
              "       -4.69389744e-03,  3.46159153e-02,  9.89513472e-03, -3.19323577e-02,\n",
              "       -2.92322831e-03,  8.60112347e-03, -6.26810789e-02, -6.04744852e-02,\n",
              "        3.51477833e-03,  2.43392773e-02, -3.83986230e-03, -2.55326228e-03,\n",
              "        1.69987567e-02, -1.73539147e-02, -3.12040132e-02, -6.33532926e-02,\n",
              "        2.07951646e-02, -1.84558555e-02, -5.12602814e-02, -1.87951582e-03,\n",
              "        2.76907012e-02, -5.98427374e-03, -4.16364800e-03,  1.85900256e-02,\n",
              "        2.03760397e-02, -2.71921251e-02, -8.70214030e-03,  3.74012254e-02,\n",
              "        3.47294062e-02,  1.70217715e-02,  2.24216357e-02,  8.47846568e-02,\n",
              "        1.85855515e-02, -4.65820879e-02,  2.71193869e-02,  1.39547270e-02,\n",
              "        6.67767599e-03, -1.43093187e-02, -2.04209215e-03,  1.03705470e-03,\n",
              "       -4.25111577e-02, -1.30037023e-02,  2.74168793e-02, -7.17787351e-03,\n",
              "       -1.69076286e-02, -1.25737088e-02, -3.88377011e-02, -3.73333171e-02,\n",
              "       -3.05227451e-02, -5.32274507e-03,  9.63143073e-03,  3.77357565e-03,\n",
              "        3.28699537e-02,  1.86027419e-02,  5.09814359e-03, -1.49951102e-02,\n",
              "       -3.94876599e-02, -1.20757194e-02,  4.17486578e-02], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELCYADbe_dWa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}